# AutoPolicy â€“ Dynamic Legal Risk Analyzer

AutoPolicy is a **web + Chrome extension** system that helps users quickly understand how risky long legal documents are â€“ such as Terms & Conditions, loan agreements, privacy policies, etc.

Instead of manually reading 20â€“30 pages, AutoPolicy:

- Extracts text from **PDFs / images (OCR)** or **live web pages**
- Splits the document into **clauses**
- Detects **risky phrases** (data sharing, account closure, fees, etc.)
- Assigns each clause a **risk severity**:
  - ğŸŸ¥ **High** â€“ red  
  - ğŸŸ§ **Medium** â€“ orange  
  - ğŸŸ¨ **Low** â€“ yellow
- Computes an overall **document grade (Aâ€“D)**
- Highlights risky clauses directly **on the website** via Chrome extension
- Stores everything in **PostgreSQL** for later review
- Supports **Marathi / Hindi translation** for clauses (for better understanding)

AutoPolicy is a **student academic project**, not a replacement for a professional lawyer.

---

Screenshots


### A. Web app â€“ login, signup & dashboard

[![Login page â€“ gradient hero + login card](screenshots/01_login_page.png)](screenshots/01_login_page.png)
[![Register page â€“ create account](screenshots/02_register_page.png)](screenshots/02_register_page.png)

[![Dashboard â€“ empty state after login](screenshots/03_dashboard_empty.png)](screenshots/03_dashboard_empty.png)
[![Dashboard â€“ documents table with risk grades](screenshots/04_dashboard_with_results.png)](screenshots/04_dashboard_with_results.png)

[![Upload dialog â€“ choosing a PDF](screenshots/05_upload_choose_file.png)](screenshots/05_upload_choose_file.png)
[![Document details â€“ donut chart + risky clauses list](screenshots/06_document_detail.png)](screenshots/06_document_detail.png)

---

### B. Chrome extension â€“ risk analysis on live website

[![Extension popup â€“ initial state on Flipkart Terms page](screenshots/07_extension_popup_open.png)](screenshots/07_extension_popup_open.png)

[![Extension â€“ page text scanned and loaded](screenshots/08_extension_page_text_loaded.png)](screenshots/08_extension_page_text_loaded.png)
[![Extension â€“ risk analysis result for full page](screenshots/09_extension_scan_result.png)](screenshots/09_extension_scan_result.png)

[![Extension â€“ analysis result for a small selected paragraph](screenshots/10_extension_selected_text_result.png)](screenshots/10_extension_selected_text_result.png)
[![Extension â€“ Marathi translation of selected text](screenshots/11_extension_translation_marathi.png)](screenshots/11_extension_translation_marathi.png)
[![Web page â€“ risky clause highlighted in yellow](screenshots/12_extension_highlighted_clause.png)](screenshots/12_extension_highlighted_clause.png)



## Problem & Motivation

Most users **blindly click â€œI Agreeâ€** on:

- Bank loan documents  
- E-commerce Terms of Use  
- App privacy policies  

These documents often contain:

- Data sharing clauses  
- Account termination rules  
- Hidden fees and charges  
- Broad indemnity clauses  

Reading and understanding everything is time-consuming and difficult, especially for **non-legal, non-technical** users.

**Goal of AutoPolicy:**  
Help users quickly identify **important/risky clauses**, understand the **overall risk level**, and highlight **exact sentences** that should be re-read carefully.

---

##  Key Features

### 1. Web Application (Flask + PostgreSQL)

- **User Authentication**
  - Register with email + password
  - Login / Logout, session handling
  - Passwords stored as **hashed values** (never plain text)

- **Document Upload & Storage**
  - Upload **PDF** or **image screenshots** (PNG/JPG/JPEG)
  - Each upload is linked to the logged-in user (`user_id`)
  - The system computes a **fingerprint** (hash) to detect duplicate documents

- **Risk Analysis Dashboard**
  - List of all documents for the logged-in user
  - For each document:
    - Filename
    - Total clauses
    - Number of risky clauses
    - Risk percentage
    - Overall grade (A/B/C/D)
    - Link to **detailed view**

- **Document Detail Page**
  - Summary information (filename, total clauses, risky clauses, grade)
  - **Donut chart (Chart.js)** showing risk distribution by category  
    (e.g. data_sharing, fees_charges, indemnity, account_closure, etc.)
  - Detailed list of **risky clauses**:
    - Clause number
    - Risk score
    - Risk tags (reasons)
    - Original clause text



### 2. Chrome Extension (Manifest V3)

- **Select or Scan Text from Any Web Page**
  - **Use selected text on page** (user highlights a section)
  - **Scan whole page** (collects visible text)
  - Sends text to backend API: `/api/analyze-text`

- **Risk Summary in Popup**
  - Risk percentage
  - Overall rating: A / B / C / D
  - Risky / total clauses
  - List of risky clauses with:
    - Clause number
    - Score
    - Tags (e.g. data_sharing, fees_charges)

- **Highlight on Live Web Page**
  - When user clicks a clause in the popup:
    - The extension finds that clause text on the page
    - Scrolls to it
    - Highlights it with color based on severity:
      - ğŸŸ¥ Red  â†’ High risk
      - ğŸŸ§ Orange â†’ Medium risk
      - ğŸŸ¨ Yellow â†’ Low risk


### 3. Risk Engine (Rule-Based NLP)

- Splits long text into **clauses** using punctuation and line breaks
- For each clause, checks for **known risky phrases**, for example:
  - Data / privacy:
    - â€œmay share your personal dataâ€
    - â€œmay disclose your informationâ€
  - Account closure:
    - â€œmay terminate your accountâ€
    - â€œmay suspend your accountâ€
  - Fees / charges:
    - â€œreserves the right to change its fee policyâ€
    - â€œnon-refundableâ€
  - Indemnity:
    - â€œyou agree to indemnifyâ€
    - â€œhold us harmlessâ€
  - Generic risk:
    - â€œat its sole discretionâ€
    - â€œwe are not liable forâ€

- Assigns each clause:
  - **Tags** (e.g. `["data_sharing", "fees_charges"]`)
  - **Score** (0â€“3) â†’ mapped to Low / Medium / High

- Overall document grade is derived from the **percentage of risky clauses**:

  - `risk% = (risky_clauses / total_clauses) * 100`

  - Grade:
    - **A** â€“ risk% â‰¤ 1  
    - **B** â€“ risk% â‰¤ 5  
    - **C** â€“ risk% â‰¤ 15  
    - **D** â€“ risk% > 15  



### 4. Clause Translation (Marathi / Hindi) â€“ Optional

To help users who are more comfortable in **Marathi** or **Hindi**:

- Backend has an API to **translate a clause** from English â†’ Marathi / Hindi
- Triggered from the UI (e.g. for a selected clause)
- Uses translation library (e.g. `deep_translator.GoogleTranslator`) or external service

> Translation is for **understanding**, not for official legal usage.



## System Architecture

### High-Level Blocks

1. **Web Frontend (Flask Templates + CSS)**  
   - `login.html`, `register.html`, `documents.html`, `document_detail.html`
   - Uses `styles.css` for a modern, dark-themed UI
   - Uses **Chart.js** for donut chart in document detail

2. **Backend (Flask)**
   - `app.py`
   - Routes:
     - `/register`, `/login`, `/logout`
     - `/` â†’ redirects to `/documents` or `/login`
     - `/documents` â†’ document list + upload
     - `/document/<id>` â†’ detailed view
     - `/api/analyze-text` â†’ risk analysis for raw text (extension)
     - `/api/translate-text` â†’ optional clause translation

3. **Processing Pipeline (CLI)**
   - `Final_text_extractor.py` â€“ extract text from PDF / images (OCR)
   - `build_latest_clauses.py` â€“ split extracted text into clauses
   - `advanced_risk_engine.py` â€“ compute risk for each clause
   - Outputs: `clauses_scored.csv` inside a `processed/<docname>/` folder

4. **Database Ingestion Script**
   - `db_ingest.py`
   - Reads `processed/<docname>/` folder:
     - Detects original file
     - Reads `clauses_scored.csv`
     - Counts total & risky clauses
     - Computes risk%, grade, fingerprint
     - Inserts into:
       - `documents` table (1 row)
       - `clauses` table (many rows)

5. **PostgreSQL Database**
   - `users` â€“ authentication
   - `documents` â€“ per document summary
   - `clauses` â€“ per clause detailed risk

6. **Chrome Extension**
   - `manifest.json` â€“ manifest v3
   - `popup.html` / `popup.js` â€“ user interface for analysis
   - `content_script.js` â€“ interacts with active web page (selection, full text, highlighting)

â€”

## How to run AutoPolicy

AutoPolicy can be run in two main ways:

1. **Locally on a single laptop** (Flask backend + PostgreSQL + Chrome extension)  
2. **Deployed on a remote server** (Flask backend + PostgreSQL on a VM / cloud)  

The core logic (risk analysis + grading) is fully local.  
Only the **translation feature** (Marathi / Hindi) needs internet.

---

### 1. Prerequisites

#### 1.1. Software

- **Python** 3.9+  
- **PostgreSQL** 13+  
- **Google Chrome / Chromium** (to load the extension)
- Git (optional, if cloning from GitHub)

#### 1.2. Python dependencies

Install from `requirements.txt` (example):

```bash
pip install -r requirements.txt

If you donâ€™t have a virtual environment yet (recommended):

cd /path/to/project_msc
python3 -m venv venv
source venv/bin/activate         # macOS / Linux
# .\venv\Scripts\activate        # Windows PowerShell

pip install -r requirements.txt

Typical dependencies used in this project:
	â€¢	Flask

	â€¢	psycopg2-binary

	â€¢	Werkzeug

	â€¢	googletrans==4.0.0rc1 (or similar; used for translations)

	â€¢	Any extra libraries used in advanced_risk_engine.py

2. Database setup (PostgreSQL)

2.1. Create database
Open a terminal and run:
psql -U postgres

Inside psql:  CREATE DATABASE autopolicy;
\c autopolicy;

2.2. Create tables
Run the SQL schema file from the project (name may vary):
psql -U postgres -d autopolicy -f schema.sql
The schema defines tables like:
	â€¢	users          â€“ login / auth users
	â€¢	documents      â€“ one row per uploaded / ingested document
	â€¢	clauses        â€“ one row per detected clause

If your schema file is named differently (e.g. create_tables.sql), replace schema.sql accordingly.

3. Configure environment variables (optional but recommended)

The backend uses environment variables with safe defaults.
You can override them if needed:

export AUTOPOLICY_DB_NAME="autopolicy"
export AUTOPOLICY_DB_USER="postgres"
export AUTOPOLICY_DB_PASSWORD=""
export AUTOPOLICY_DB_HOST="localhost"
export AUTOPOLICY_DB_PORT="5432"

export AUTOPOLICY_SECRET_KEY=â€œsome-long-random-string"

If you skip this step, the defaults in app.py will be:
	â€¢	DB name: autopolicy
	â€¢	DB user: postgres
	â€¢	Password: empty
	â€¢	Host: localhost
	â€¢	Port: 5432
	â€¢	Secret key: â€œchange-me-for-production"

4. Running the backend locally (Flask + PostgreSQL)

From the project root (where app.py is):

cd /path/to/project_msc
source venv/bin/activate      # if using virtual env
python3 app.py

You should see something like:

 * Serving Flask app 'app'
 * Debug mode: on
 * Running on http://127.0.0.1:5000

This starts the AutoPolicy backend on:

http://127.0.0.1:5000
This address is used both by:
	â€¢	The web app (dashboard & login pages)
	â€¢	The Chrome extension (for /api/analyze-text and /api/translate-text)

5. Running the web app (dashboard)
	1.	Make sure Flask server is running (python3 app.py).

	2.	Open a browser and go to:

     	3.	Register a user:
	â€¢	Click on â€œCreate account / Registerâ€.
	â€¢	Fill email + password.
	â€¢	The user is stored in the users table.

	4.	Login:

	â€¢	Use the same email and password.
	â€¢	After login, you will be redirected to /documents (Dashboard).

	5.	Upload + analyze a document from the dashboard:

	â€¢	On /documents, use the Upload section:
	â€¢	Choose file (PDF / PNG / JPG / JPEG).
	â€¢	Click Upload & Analyze.
	â€¢	Under the hood, for each upload, the backend:
	1.	Saves the file into uploads/.
	2.	Calls advanced_risk_engine.py to:
	â€¢	Extract text,
	â€¢	Split into clauses,
	â€¢	Generate processed/<base_name>/clauses_scored.csv.
	3.	Calls db_ingest.py processed/<base_name> <current_user_id> to:
	â€¢	Compute clause-level risk again (rule-based),
	â€¢	Insert into documents and clauses tables.

	6.	Dashboard table:
	â€¢	Shows one row per document:
	â€¢	Original filename,
	â€¢	Total clauses,
	â€¢	Risky clauses,
	â€¢	Risk percentage,
	â€¢	Overall grade (Aâ€“D).

	7.Per-document detail view:
	â€¢	Click â€œViewâ€ to open /document/<id>.
	â€¢	This shows:
	â€¢	Summary (filename, total clauses, risky %, rating),
	â€¢	A Pie chart of risk types (e.g. data_sharing, fees_charges, generic_risk,â€¦),
	â€¢	Detailed list of all risky clauses with:
	â€¢	Clause number,
	â€¢	Risk score (1â€“3),
	â€¢	Risk reason tags,
	â€¢	Full clause text.

â¸»

6. Running the Chrome extension locally

The extension expects the backend at:
http://127.0.0.1:5000

6.1. Load the extension in Chrome
	1.	Open chrome://extensions/ in Chrome.
	2.	Enable Developer mode (top-right).
	3.	Click â€œLoad unpackedâ€.
	4.	Select the extension folder, for example: /path/to/project_msc/extension

which contains:
	â€¢	manifest.json
	â€¢	popup.html
	â€¢	popup.js
	â€¢	popup.css
	â€¢	content_script.js

	5.	The AutoPolicy icon should now appear in the Chrome toolbar.

6.2. Analyze a live web page
	1.	Make sure python3 app.py is running.
	2.	Open any legal / terms-of-use page in Chrome.
	3.	Select some text (or leave it to analyze full page).
	4.	Click the AutoPolicy extension icon.
	5.	In the popup:
	â€¢	Click â€œUse Selectionâ€ or â€œFull Pageâ€.
	â€¢	Click â€œAnalyze riskâ€.

The extension will:
	â€¢	Send the text to POST http://127.0.0.1:5000/api/analyze-text.
	â€¢	Show:
	â€¢	Total clauses,
	â€¢	Number of risky clauses,
	â€¢	Grade,
	â€¢	List of risky clauses.
	â€¢	Let you:
	â€¢	Click on a clause to highlight it back on the page (yellow / orange / red).
	â€¢	Request Marathi / Hindi translation for that clause.


## Project Structure (Example)

```text
project_root/
â”œâ”€â”€ app.py                    # Flask web server (routes, APIs, auth)
â”œâ”€â”€ db_ingest.py              # Ingest processed results into PostgreSQL
â”œâ”€â”€ Final_text_extractor.py   # (Pipeline) Extract text from PDFs/images
â”œâ”€â”€ build_latest_clauses.py   # (Pipeline) Create clauses from text
â”œâ”€â”€ advanced_risk_engine.py   # (Pipeline) Risk scoring per clause
â”œâ”€â”€ risky_phrase_detector.py  # (Optional) More detailed risk logic
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html            # Redirect home
â”‚   â”œâ”€â”€ login.html            # Login screen
â”‚   â”œâ”€â”€ register.html         # Sign-up screen
â”‚   â”œâ”€â”€ documents.html        # Dashboard + upload + table
â”‚   â””â”€â”€ document_detail.html  # Document detail + chart + clauses
â”œâ”€â”€ static/
â”‚   â””â”€â”€ styles.css            # Global styling for the web app
â”œâ”€â”€ extension/
â”‚   â”œâ”€â”€ manifest.json         # Chrome manifest
â”‚   â”œâ”€â”€ popup.html            # Popup UI
â”‚   â”œâ”€â”€ popup.js              # Logic for API calls + list rendering
â”‚   â””â”€â”€ content_script.js     # Reads page text + applies highlights
â””â”€â”€ screenshots/              # For README images (not required by code)
    â”œâ”€â”€ register.png
    â”œâ”€â”€ login.png
    â”œâ”€â”€ dashboard_documents.png
    â”œâ”€â”€ document_detail.png
    â”œâ”€â”€ extension_popup.png
    â””â”€â”€ extension_highlight.png

## What happens internally when I upload a file? (File-level view)

This section explains **only the file-level flow** when a user uploads a PDF/image from the web dashboard â€” which folders and files are created, and what each file contains.

We ignore the Chrome extension here and focus on:

1. Files created in the project folder (`uploads/` and `processed/`).
2. What is stored inside those files.
3. Which step of the pipeline creates them.

---

### Step 0 â€“ Initial state

Before uploading anything, the project already has these folders:

```text
project_root/
â”œâ”€â”€ app.py
â”œâ”€â”€ advanced_risk_engine.py
â”œâ”€â”€ db_ingest.py
â”œâ”€â”€ templates/
â”œâ”€â”€ static/
â”œâ”€â”€ uploads/      # exists, usually empty at the start
â””â”€â”€ processed/    # exists, contains previous runs (if any)

### Step 1 â€“ Upload from dashboard â†’ file saved into uploads/

Action: User logs in â†’ opens /documents â†’ chooses a PDF/image â†’ clicks â€œUpload & Analyzeâ€.

What Flask does in /documents (POST):
	1.	Reads the uploaded file from the HTTP request.
	2.	Sanitizes the name (using secure_filename).
	3.	Saves it into the uploads/ folder.
Example:

If the user uploads SBI_Loan.pdf, this file is created:
uploads/
â””â”€â”€ SBI_Loan.pdf
Contents of uploads/SBI_Loan.pdf:
	â€¢This is exactly the original file the user uploaded (PDF / PNG / JPG / JPEG).
	â€¢No modification, just stored on disk so the pipeline can read it.

### Step 2 â€“ Text extraction + clause splitting â†’ files in processed/<docname>/

After saving the file, app.py runs:
python3 advanced_risk_engine.py uploads/SBI_Loan.pdf
advanced_risk_engine.py does:
	1.Detects file type (.pdf vs .png/.jpg/.jpeg).
	2.Extracts the full raw text:
	    â€¢For PDFs: via a PDF text extractor.
	    â€¢For images: via OCR.
	3.Splits the text into clauses using a regex like:
                       râ€(?<=[.!?;])\s+|\n+"
	4.Creates a subfolder under processed/ named after the base file name (without extension).

For SBI_Loan.pdf, the folder structure becomes:
processed/
â””â”€â”€ SBI_Loan/
    â”œâ”€â”€ SBI_Loan.pdf           # (optional) copy of the original file
    â”œâ”€â”€ extracted_text.txt     # full raw text of the document
    â””â”€â”€ clauses_scored.csv     # one row per clause

### 2.1 processed/SBI_Loan/extracted_text.txt
	â€¢Created by: advanced_risk_engine.py
	â€¢Format: Plain UTF-8 text file.
	â€¢Content: The entire document text in one file, as extracted from the PDF/image.

Example (simplified):
SBI Loan Agreement

1. You agree to repay the loan with interest...
2. The bank may change interest rates without prior notice...
3. We are not liable for...
â€¦

Purpose:
	â€¢Debugging / inspection: you can quickly see what text the pipeline actually â€œsawâ€.
	â€¢Good for showing to teachers/interviewers: â€œThis is the cleaned text we got from OCR/PDF.â€

### 2.2 processed/SBI_Loan/clauses_scored.csv
â€¢Created by: advanced_risk_engine.py
â€¢Updated logically by: db_ingest.py (recomputes risk, but does not necessarily rewrite the file; it uses the data to write into DB).
â€¢Format: CSV with a header row.

Example (before DB ingest):
clause_id,text,model_is_risky,model_risk_reason,model_risk_score
1,"You agree to repay the loan with interest...",FALSE,,0
2,"The bank may change interest rates without prior notice",FALSE,,0
3,"We are not liable for any indirect damages",FALSE,,0
â€¦

Columns:
	â€¢clause_id
	â€¢Clause serial number starting from 1.
	â€¢text
	â€¢Exact text of that clause (one row = one clause).
	â€¢model_is_risky (placeholder initially)
	â€¢Initially might be FALSE or 0 for all rows.
	â€¢model_risk_reason (placeholder initially)
	â€¢Empty or very basic; real tags are recomputed later.
	â€¢model_risk_score (placeholder initially)
	â€¢0 for all clauses at first.

Purpose:
	â€¢This file is the bridge between the OCR/PDF parsing world and the     
	database world.
	â€¢Itâ€™s a clean, structured list of clauses that db_ingest.py can consume.

### Step 3 â€“ Risk computation + DB insert (no new files, only DB rows)

After the processed folder is ready, app.py runs:
python3 db_ingest.py processed/SBI_Loan <user_id>

Example for user id 1:
python3 db_ingest.py processed/SBI_Loan 1

Inside db_ingest.py:
	1.Reads processed/SBI_Loan/clauses_scored.csv.
	2.For each clause row, recomputes risk:

                  is_risky, reasons, score = score_clause_simple(text)
using rule-based patterns like:
â€˜May shear your personal dataâ€™-> data_sharing
â€¢"we are not liable for" â†’ generic_risk
â€¢"you agree to indemnify" â†’ indemnity
	
3.	Counts:
	â€¢	total_clauses
	â€¢	risky_clauses
	â€¢	risky_percent
	â€¢	overall_rating (A/B/C/D)

4.	Inserts:
	â€¢	ONE row into documents table.
	â€¢	MANY rows into clauses table.

Important:
In this step, no extra files are created on disk. All work is:
	â€¢	Reading extracted_text.txt / clauses_scored.csv.
	â€¢	Writing rows into PostgreSQL.
Internally, PostgreSQL stores these rows in its data directory (heap files, 8KB pages, WAL, etc.), but from the project perspective you can treat it simply as:
	â€¢	Metadata â†’ documents table
	â€¢	Detailed per-clause data â†’ clauses table

### Step 4 â€“ Dashboard refresh (read-only, no new files)

When the browser reloads /documents after â€œPipeline completedâ€:
	1.	app.py reads from documents (for that user_id).
	2.	No new files are created; it just queries the DB.
	3.	The uploaded document now appears in the dashboard table with:
	â€¢	Filename
	â€¢	Total clauses
	â€¢	Risky clauses
	â€¢	Risk %
	â€¢	Grade

Clicking â€œViewâ€ on any row uses the document_id to query:
	â€¢	documents table (summary),
	â€¢	clauses table (risky clauses),
	â€¢	builds the pie chart and detail list.

Again, this is read-only with respect to files. No new files are added here.
â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

## What happens internally when I use the Chrome extension? (Step-by-step)

This section explains **how the Chrome extension talks to the AutoPolicy backend** and what happens when a user selects text on a web page and clicks **â€œAnalyze riskâ€** or **â€œTranslateâ€**.

Unlike the dashboard flow, the extension:

- Does **not** create new files on disk.
- Works entirely with:
  - Browser memory (DOM, JS objects),
  - HTTP calls to the local Flask backend (`http://127.0.0.1:5000`),
  - Temporary highlights on the page.

---

### Step 0 â€“ Extension files (what ships inside the `.crx` / unpacked extension)

Inside the extension folder, we mainly have:

```text
extension_root/
â”œâ”€â”€ manifest.json          # Chrome extension configuration
â”œâ”€â”€ popup.html             # Small UI that opens when user clicks the icon
â”œâ”€â”€ popup.js               # Logic for buttons, API calls, UI updates
â”œâ”€â”€ popup.css              # Styling for the popup
â””â”€â”€ content_script.js      # Injected into every page the user opens

High-level roles:
	â€¢manifest.json
	â€¢	Tells Chrome:
	â€¢	Which files are part of the extension,
	â€¢	Permissions (activeTab, storage, scripting),
	â€¢	Which script to inject into web pages (content_script.js),
	â€¢	Which file is the popup (popup.html),
	â€¢	Which URLs the extension is allowed to call (http://127.0.0.1:5000/*).
	â€¢popup.html + popup.js
	â€¢	Renders the small panel you see when clicking the extension icon.
	â€¢Lets the user:
	â€¢	Grab selected text or full page text.
	â€¢	Send it to the AutoPolicy backend for risk analysis.
	â€¢	See the list of risky clauses and overall grade.
	â€¢	Highlight a clause back on the page.
	â€¢	Translate a clause to Marathi or Hindi.
	â€¢content_script.js
	â€¢	Runs inside each web page.
	â€¢	Can read the text that the user selected.
	â€¢	Can modify the page (for highlight).
	â€¢	Communicates with the popup via chrome.runtime.sendMessage.

â¸»

Step 1 â€“ Page loads â†’ content script + highlight styles are injected

Whenever you open a new tab or navigate to a page, Chrome injects:
content_script.js
(because of the "content_scripts" section in manifest.json).

Internally, content_script.js does:
	1.Injects CSS for highlights only once per page:
	â€¢It creates a <style> tag with classes like:
                . Autopolicy -highlights
                . autopolicy-riksy- low (Yellow)
                . autopolicy-riksy- medium (Orange)
                 . autopolicy-riksy- high (Red)

â€¢	Each highlight has a small pulse animation to draw attention.

	2.Defines helper functions:
	â€¢getSelectionText()
	â€¢	Returns the text currently selected by the user on the page.
	â€¢	getFullPageText()
	â€¢	Returns the entire document.body.innerText as plain text.
	â€¢	highlightClauseOnPage(text, severity, doScroll)
	â€¢	Finds a matching snippet in the page HTML using a regex.
	â€¢	Wraps the matching text in:
   
       <span class="autopolicy-highlight autopolicy-risk-XXX autopolicy-focus-pulse">
  ...clause text...
</span>

          â€¢Scrolls the page so that the highlighted clause is centered.
	â€¢Removes the pulse class after the animation.
3.Sets up a message listener:

chrome.runtime.onMessage.addListener(â€¦)

It listens for messages from the popup:
	â€¢	GET_SELECTION â†’ reply with { text: selectedText }
	â€¢	GET_FULL_PAGE_TEXT â†’ reply with { text: fullPageText, url: window.location.href }
	â€¢	HIGHLIGHT_CLAUSE â†’ call highlightClauseOnPage(...)

Files created in this step:
	â€¢	None. Everything is done in browser memory and DOM.

Step 2 â€“ User opens the popup and grabs text

Action: User clicks the AutoPolicy extension icon in the toolbar.

This opens popup.html, which is connected to popup.js.

Inside the popup:
	1.	User chooses input source:
	â€¢	â€œUse selectionâ€ â†’ ask the content script for just the selected text.
	â€¢	â€œFull pageâ€ â†’ ask for innerText of the whole page.
	2.	popup.js sends a message to the content script:
	â€¢	To get selection:  { "type": "GET_SELECTION" }
 		â€¢	To get full page text: { "type": "GET_FULL_PAGE_TEXT" }
	3.content_script.js replies with the text, and popup shows it in a text area, like:  [Selected or full-page text hereâ€¦]
Files created in this step:
	â€¢	Still none. Only messages between popup and content script.

Step 3 â€“ Risk analysis via backend API (/api/analyze-text)

Action: User clicks â€œAnalyze riskâ€ in the popup.

Internally, popup.js:
	1.	Reads the text from the popupâ€™s text area.
	2.	Optionally includes user_email (for future multi-user features).
	3.	Sends an HTTP POST to the local backend:

  POST http://127.0.0.1:5000/api/analyze-text
Content-Type: application/json

{
  "text": "<selected or full-page text>",
  "user_email": "<logged-in email (optional)>",
  "page_url": "<current tab URL (optional)>"
}

Backend side: app.py â†’ /api/analyze-text

The Flask route /api/analyze-text:
	1.	Gets the raw text from JSON.
	2.	Splits it into clauses using the regex: râ€(?<=[.!?;])\s+|\n+"
	3.	For each clause, calls the rule-based risk engine:
          is_risky, reasons, score = score_clause_simple(clause_text)
    Example rules:
	â€¢Phrases like "may share your personal data" â†’ tag data_sharing, score 3.
	â€¢"we are not liable for" â†’ tag generic_risk, score 2.
         â€¢â€non-refundable", "all sales are final" â†’ tag fees_charges, score 2.

	4.Builds:
	â€¢	total_clauses
	â€¢	risky_clauses list (clause number, text, tags, score)
	â€¢	risky_percent
	â€¢	overall_rating (A/B/C/D)
	â€¢	risk_breakdown (tag â†’ count)
	5.Returns a JSON response like:
{
  "ok": true,
  "total_clauses": 42,
  "risky_clauses": [
    {
      "clause_number": 5,
      "text": "We are not liable for indirect or consequential damages...",
      "score": 2,
      "reasons": ["generic_risk"]
    },
    ...
  ],
  "risky_percent": 9.52,
  "overall_rating": "C",
  "risk_breakdown": {
    "generic_risk": 3,
    "data_sharing": 1
  },
  "risky_clauses_count": 4,
  "grade": "C"
}

Important:
The extension flow does not store anything in the database during this API call.
/api/analyze-text is a stateless analysis endpoint used for quick checks.

Step 4 â€“ Popup UI renders results + sends highlight commands

Once the popup receives the JSON:

	1.It shows a summary at the top, for example:
	â€¢	â€œTotal clauses: 42â€
	â€¢	â€œRisky clauses: 4â€
	â€¢	â€œGrade: C (medium risk)â€

	2.It lists each risky clause with:
	â€¢	Clause number.
	â€¢	Short snippet of the text.
	â€¢	Risk score / tags.

	3.For each clause row, there is a â€œHighlight on pageâ€ (or click action).
When the user clicks Highlight, popup.js sends a message to the content script:
{
  "type": "HIGHLIGHT_CLAUSE",
  "text": "<clause text>",
  "severity": "low" | "medium" | "high"
}

â€¢	The severity is derived from the score:
	â€¢	score = 1 â†’ "low" (yellow).
	â€¢	score = 2 â†’ "medium" (orange).
	â€¢	score = 3 â†’ "high" (red).

	4.The content script receives this message and calls:

                   highlightClauseOnPage(clauseText, severity, true);
Which:
	â€¢Locates a matching snippet in document.body.innerHTML.
	â€¢Replaces the first match with:
<span class="autopolicy-highlight autopolicy-risk-high autopolicy-focus-pulse">
  ...text...
</span>

	â€¢Scrolls smoothly so that the span is in the center.
	â€¢Removes the pulse after ~1.2 seconds.

Files created in this step:
	â€¢None. This step only updates the web page DOM temporarily.

Step 5 â€“ On-demand translation (Marathi / Hindi)

The popup also supports per-clause translation into Marathi or Hindi.

Action: User selects a clause in the popup and chooses â€œTranslate â†’ Marathi/Hindiâ€.

Internally:
	1.popup.js sends a POST to: 

POST http://127.0.0.1:5000/api/translate-text
Content-Type: application/json

{
  "text": "<clause text>",
  "target_lang": "marathi" | "hindi" | "mr" | "hi"
}
Backend side: app.py â†’ /api/translate-text
	1.	Maps the target_lang:
	â€¢	"marathi" â†’ "mr"
	â€¢	"hindi" â†’ "hi"
	2.	Uses googletrans.Translator:
  			translator.translate(text, dest=lang_code)

	3.	Returns:{
  "ok": true,
  "translated_text": "à¤®à¤°à¤¾à¤ à¥€ / à¤¹à¤¿à¤‚à¤¦à¥€ à¤­à¤¾à¤·à¥‡à¤¤à¥€à¤² à¤•à¥à¤²à¥‰à¤œ...",
  "target_lang": "mr"
}
The popup shows the translated clause right below the original English clause.

Again, no files are written to disk â€” itâ€™s just API in / API out.
